<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300&display=swap" rel="stylesheet"> 

  <title>SLIC-Calib</title>
  <style>
    *{
    font-family: 'Roboto', sans-serif;
    padding: 0;
    margin: 0;
    outline: none;
    }
  </style>
</head>

<body>
  <div class="container">
    <br>
    <div style="text-align: center;">  
      <h1>
        <span style="font-weight: 900;">SLIC-Calib</span>: Single-Point LiDAR and Camera Calibration Leveraging Manhattan World
      </h1>

      <div style="margin-top: 15px;">
        <span style="margin-right: 15px; font-size: 1.3em;"><a href="" target="_blank">Anonmous authors<sup>1</sup></a></span>
    
      </div>
      
<div class="row">
    <div class="col-sm-6 col-sm-offset-3 text-center">
        <ul class="nav nav-pills nav-justified">
            <li>
                <a href="">
                    <img src="img/paper_image.png" height="60px">
                    <h4><strong>Paper</strong></h4>
                </a>
            </li>
            <li>
                <a href="">
                    <img src="img/youtube_icon.png" height="60px">
                    <h4><strong>Video</strong></h4>
                </a>
            </li>
            <li>
                <a href="">
                    <img src="img/github.png" height="60px">
                    <h4><strong>Code</strong></h4>
                </a>
            </li>
        </ul>
    </div>
</div>
    <div class="row">
      <div class="col-md-12 col-sm-12 col-xs-12">
        <div class="embed-responsive embed-responsive-21by9">
          <video controls loop muted autoplay class="embed-responsive-item">
            <source src="gfx/room_videos/n3_text.mp4" type="video/mp4">
          </video>
        </div>
        <p class="text-center" style="font-size: 1.5em;">
          <span style="font-weight: bold;">RegNeRF</span> enables realistic view synthesis from as few as 3 input
          images.
        </p>
      </div>
    </div>
    <div style="margin-top: 30px;">
      <h2 class="text-center">
        Abstract
      </h2>
      <p style="font-style: normal; text-align: justify; margin-bottom: 5px;">
We propose a novel calibration method between single-point LiDAR and camera sensors utilizing an easy-to-build customized calibration board satisfying the Manhattan world (MW).
Previous approaches for LiDAR-camera (LC) calibration focus on line and plane correspondences.
However, they require dense point clouds from heavy LiDAR to simplify alignment; otherwise, these approaches fail for extremely sparse LiDAR.
The compact size and lightweight single-point LiDARs make them ideal for micro-robotics where size and weight are constrained.
To address these gaps, we present a new extrinsic calibration method with a new calibration board, which rotates like a door to capture geometric features and align them with images.
Once we find an initial estimate, we refine the relative rotation by minimizing the angle difference between the grid orientation of the checkerboard and the MW axes.
We demonstrate the effectiveness of the proposed method through various LC configurations, achieving its capability and high accuracy compared to other state-of-the-art approaches.
We release our calibration toolkit, source codes, and how to make the calibration target boards at: href="https://slic-calib.github.io/".
      </p>
    </div>
    <div style="margin-top:10px;">
      <h2 class="text-center">
        Video
      </h2>
      <div class="embed-responsive embed-responsive-16by9">
        <iframe class="embed-responsive-item" src="" allowfullscreen></iframe>
      </div>
    </div>
    <div style="margin-top: 50px;">
      <div class="text-center">
        <h2>
          Method Overview
        </h2>
        <img src="gfx/teaser.svg" width=100% class="img-fluid" alt="Responsive image">
      </div>
      <div style="margin-top: 35px;">
        <p>
          (<span class="text-danger">red cameras</span>) and <span
            style="font-weight: bold;"> 
        </p>
      </div>
    </div>
    <div style="margin-top:50px;">
      <h2 class="text-center">
        Results
      </h2>
      <h4>View Synthesis from 3 Input Views</h4>
      <p>
        While mip-NeRF leads to degenerate view synthesis and predicted scene geometry, our method enables realistic
        view synthesis from 3 input views.
      </p>
      <div class="row">
        <div class="col-md-12 col-sm-12 col-xs-12 gallery">
          <div class="embed-responsive embed-responsive-21by9">
            <video controls loop muted autoplay class="embed-responsive-item">
              <source src="gfx/room_videos/n3_text.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <h4>View Synthesis from 6 Input Views</h4>
      <p>
        For 6 input views, mip-NeRF improves but predicted renderings and the optimized scene geometry still contain
        floating artifacts. Our approach leads to smooth predicted scene geometry and realistic novel views.
      </p>
      <div class="row">
        <div class="col-md-12 col-sm-12 col-xs-12 gallery">
          <div class="embed-responsive embed-responsive-21by9">
            <video controls loop muted autoplay class="embed-responsive-item">
              <source src="gfx/room_videos/n6_text.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <h4>View Synthesis from 9 Input Views</h4>
      <p>
        For 9 input views, mip-NeRF and our method both lead to high-quality view synthesis. For mip-NeRF, small
        floating artfiacts for far-away novel views near the table are still visible while our predicted scene geometry
        appears more realistic.
      </p>
      <div class="row">
        <div class="col-md-12 col-sm-12 col-xs-12 gallery">
          <div class="embed-responsive embed-responsive-21by9">
            <video controls loop muted autoplay class="embed-responsive-item">
              <source src="gfx/room_videos/n9_text.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <div style="margin-top:50px;">
        <h2 class="text-center">
          More Results
        </h2>
        <!-- <p style="margin-top: 10px;">
          For more results, check out <a href="comparisons.html" target="_blank">the baseline comparisons</a> or <a
            href="ours.html" target="_blank">more view synthesis results from our method</a>.
        </p> -->
        <p>For more results, check out:</p>
      </div>
      <div>
        <h2 class="text-center" style="margin-top: 30px;">
          Citation
        </h2>
        <p>
         
        </p>
  
      </div>
      
      <!-- Optional JavaScript -->
      <!-- jQuery first, then Popper.js, then Bootstrap JS -->
      <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
        integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
        integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
        crossorigin="anonymous"></script>
      <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
        integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
        crossorigin="anonymous"></script>
</body>

</html>
